We present a novel approach to understanding and improving large language models through complex network analysis. By representing the internal attention mechanisms of transformers as multi-layer networks, we uncover fundamental patterns in how information flows through these models. Our analysis reveals that successful language models exhibit small-world properties and scale-free degree distributions in their attention graphs, similar to biological neural networks. We demonstrate that these network properties strongly correlate with model performance on downstream tasks, providing new insights into what makes language models effective. Furthermore, we show that explicitly optimizing for these network properties during training leads to models that are both more interpretable and more sample-efficient. Our work bridges the gap between network science and deep learning, offering principled ways to design and analyze the next generation of language models.